# -*- coding: utf-8 -*-
"""proyek_nlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14kFEJUwTAqaEZYk-4weu3N9CUgQdOEoV

## **PROYEK PERTAMA BELAJAR PENGEMBANGAN MACHINE LEARNING**
## **Membuat Model NLP dengan TensorFlow**
#Nama : Addina Dwi Nugroho
#Email : addin27nugroho@gmail.com
"""

#sambung google colab ke google drive
from google.colab import drive
drive.mount('/content/drive')

#baca dataset
import pandas as pd
df = pd.read_csv("/content/drive/My Drive/dataset/Womens Clothing E-Commerce Reviews.csv")

#lihat info dataset
df.info()

#tampilkan 5 dataset teratas
df.head()

df = df[['Review Text','Department Name']] #karena kita hanya membutuhkan kolom 'Review Text' dan 'Department Name', maka kita bisa hapus kolom yang lain

df.dropna(axis=0, inplace=True) #hapus data yang memiliki null value

df.info() #lihat kembali info dataset

df.head() #lihat kembali dataset teratas

#Karena label berupa data kategorikal, maka perlu dilakukan proses one-hot-encoding
category = pd.get_dummies(df['Department Name'])
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='Department Name')
df_baru

#ubah nilai-nilai dari dataframe ke dalam tipe data numpy array menggunakan atribut values agar dapat diproses oleh model
review = df_baru['Review Text'].values
label = df_baru[['Intimate', 'Dresses', 'Bottoms', 'Tops', 'Jackets', 'Trend']].values

#bagi data untuk training dan untuk testing
from sklearn.model_selection import train_test_split
review_latih, review_test, label_latih, label_test = train_test_split(review, label, test_size=0.2)

#ubah setiap kata pada dataset ke dalam bilangan numerik dengan fungsi Tokenizer, kemudian konversikan setiap sampel menjadi sequence
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(review_latih) 
tokenizer.fit_on_texts(review_test)
 
sekuens_latih = tokenizer.texts_to_sequences(review_latih)
sekuens_test = tokenizer.texts_to_sequences(review_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

#latih data dengan model sequential sesuai kriteria submission
import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(6, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

#Gunakan Callback agar proses otomatis berhenti ketika akurasi model memenuhi kriteria (81%)
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy')>0.81):
      print("\nAKURASI MODEL LEBIH DARI 81%! PELATIHAN MODEL DIHENTIKAN.")
      self.model.stop_training = True

callbacks = myCallback()

#latih model dengan model.fit
num_epochs = 30
history = model.fit(padded_latih, label_latih, epochs=num_epochs, 
                    validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])

#visualisasi hasil pelatihan model
import matplotlib.pyplot as plt #import library untuk visualisasi data

train_acc = history.history['accuracy'] #akurasi training
val_acc = history.history['val_accuracy'] #akurasi validation
train_loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(train_acc)) #jumlah epoch

plt.figure(figsize=(15,5))
plt.plot(epochs, train_acc, marker='o', color='blue', label='Akurasi Training')
plt.plot(epochs, val_acc, marker='o', color='red', label='Akurasi Validasi')
plt.legend()
plt.title('Akurasi Pelatihan Model', pad=30, fontsize=30)
plt.xlabel('Epoch', fontsize=20)
plt.ylabel('Nilai Akurasi', fontsize=20)
plt.grid(color='darkgray', linestyle=':', linewidth=0.5)
plt.xticks([0,5,10,15,20])
plt.ylim(ymin=0)
plt.show()

plt.figure(figsize=(15,5))
plt.plot(epochs, train_loss, marker='o', color='blue', label='Loss Training')
plt.plot(epochs, val_loss, marker='o', color='red', label='Loss Validasi')
plt.legend()
plt.title('Loss Pelatihan Model', pad=30, fontsize=30)
plt.xlabel('Epoch', fontsize=20)
plt.ylabel('Nilai Loss', fontsize=20)
plt.grid(color='darkgray', linestyle=':', linewidth=0.5)
plt.xticks([0,5,10,15,20])
plt.ylim(ymin=0)
plt.show()